<IntroPost>
Rakis is a decentralized inference network for AI that runs entirely in the browser. It’s as decentralized as I could make it. There are no servers, and the code I run (which is fully open-source) is the same as anyone else’s.

It’s live as of today, and completely open-source. In it is a new browser-based stack for inference (running llms, computing binary embeddings, p2p primitives, packets, etc) and a new consensus mechanism for p2p inference.

(Don’t run anything you don’t trust. Here’s all of the important code compressed into a file, so you can drop it into Claude or ChatGPT and ask questions. You can also [get it on IPFS] if you want something with fewer central parties in between - and you’re okay without upgrades for now.)

As of today, it can - and has - run distributed inference on multiple models, arrived at deterministic repeatable consensus about those outputs, entirely through a network of client-side pages.

The only caveat is that all of it was written by me over a few weeknights. If you search for `TODO`s in the codebase, you’ll see me with full knowledge watch the right way to do things go by me. (The TODOs are also wonderful places to contribute.) A lot of the code was written - as an AI-assisted generalist like me would - with little knowledge and a lot of engineering approximations - at 3 am.

But it works, and it’s fun.

Go run it. Any WebGPU compatible browser should be able to let you be a contributing node, and almost any browser should let you send inference requests and see the results. From this point, all bets are off. I’ll report back in a week how this goes, once I’m back from break.

(Also written by me - but not deployed anywhere but testnets - are the prototypes and typespecs for smart contracts that can serve as an interface between the Rakis network and any popular chain with a smart-contract VM.

So why does it exist?

## The reason(s)

The main reason is that I wanted to take a break, and after doing a 5kms every day and then 10ks, I wanted to replace break time with some building. Once I did, this was the obvious choice - for positive and negative reasons.

The biggest positive reason why is that it would just be cool to have a decentralized inference network - one that can connect to other networks. If you can add an LLM() instruction to the modern smart contract instruction set, you make two things happen simultaneously. Cryptocurrency networks now gain probability computation, advanced NLP, and a whole bunch more creativity. On the other hand, you give agents immutability, disconnect them from their makers, and hand them payment rails. Imagine self executing trusts and grants that are mostly prompts, agents that pay for their own API costs, sybil detection - the possibilities grow the more I consider them.

The second biggest reason is [wasm-ai]. Having run models in the browser before, I knew this was possible - but it would take a lot of engineering time. Building this project has been my way of proving to myself that the browser really is ready to take on a lot more - even with my lack of skill there. We’ll do a deep dive on the technical architecture in the next part, but the sheer number of things working to make this happen are in no way trivial.

I couldn’t shake the idea of having a peer-to-peer network that produced useful output and ran entirely client-side. Browsers have a way of democratising access - everyone has one, and the variation in client-side compute and size is positively democratic compared to what exists on the server side. Most inference networks I’ve seen so far have large H100s run by well-funded actors that bully and centralize the whole thing (much like midgame BTC or ETH), and it’s harder to do with browsers. Rakis also supports follower nodes, so you can load it on an iPad or a phone, and send inference requests without participating (but I’d appreciate you doing both!)

There’s something deeply romantic about a single compiled web-page - much like the early encyclopedias that came in CDs - that can be served statically, saved to your machine, that is yours to inspect and modify, can’t be changed without permission once you have it, and there are no other hidden parts of the network.

If you clicked the link to Rakis at the beginning and set a password, you’re now part of the network. Welcome.


Now for the other side. As someone who has worked in both the peer-to-peer smart contract and AI spaces, I get a number of due diligence requests for AIxCrypto AIxP2P companies. There are some [genuinely] [good] ones out there - but almost all of them have the following properties:
They don’t have a working, open-source prototype. Huge roadmaps, but nothing real.
They have no real solution to the fact that language models aren’t deterministic, and consensus is hard. You can’t have prediction markets solve everything, and most seem to be waiting until either trusted compute modules or ZKML are able to run large language models at scale - both of which are clearly [pipe dreams] at the moment.
—

Now this isn’t me saying this is all bad - a good number of teams have their hearts in the right place, and are genuinely trying to solve the key problems in decentralized inference. I’d like to help those guys - I’m hoping some part of this is useful.


## Problem 1: AIs play with dice

The biggest problem in p2p inference is that executing large AI models is never deterministic. Given the sheer number of decimal multiplications, multiple runs with the same prompt at temperature zero with the same model can product different results.

To give you an example - here’s me running the same prompt on the same model, computer and settings, with completely different outputs!

[picture]

It’s bad enough that even [embeddings] can’t be accepted as deterministic.

This is a big issue for peer-to-peer networks, where the traditional method of consensus has been to simply recheck each other’s work. If you don’t trust a Bitcoin node, you can get the root, the transactions, and simply recompute the tip. Without it, you’re left trusting that whoever conducted the inference has been truthful, at which point you might as well trust [Sam] for better results.

## Problem 2: Oracles

The second problem is that a decentralized system can’t easily interface with a centralized system, while preserving the same guarantees and lack of trust. This is why oracles are still an open problem with [different solutions] implying separate tradeoffs. How do you build an oracle for general purpose text with no simple way to compare things?

## Problem 2: Sybil and freerides

Once you have a network, you run into some causal chains. Inference isn’t free - it might be in a boom, but not once the dust settles. Someone had to spend depreciating hardware and electricity to get you your tokens. That means an economic incentive needs to exist, somewhere down the line - for any production inference network. Once you introduce an incentive - token, cash, etc - your network - whether it was designed to or not - needs to get byzantine tolerant really, *really* quickly.

Two main problems exist - that I can see:
Sybil - you need some way to prevent one person from pretending to be 50, and collecting 50 payouts.
Freerides - how do you stop people from copying someone else’s homework and collecting a reward?

## Problem 3: Counterengineering ML

This is something [vitalik] kindly pointed out some time ago, but [“AI as use”] (as he calls it) is vulnerable to ML counter-engineering, through prompt-engineering and detailed study of the underlying models. Permissionless systems also often have the problem that they’re open-source by design and by default, so it’s fair to presume that the models being used are open for study - and to be exploited.

## Problem 4: Secure inference

This is another open problem - and definitely out of scope for Rakis, but worth mentioning. Due to the nature of modern AI models, they need plaintext to operate on, which means that your prompt (and information) will need to be completely exposed right before it goes into a model.



Here’s how we solve these problems:

# Implemented Solutions

(If you’d like well-labelled process and schema diagrams with an in-depth explanation, [my friend lumie] has got your back. This will be a short and simple overview of how things work. We’ll have another post later about the importance of binary and matroshka embeddings, the storage mechanisms we use, and the reasons behind certain choices.)

### Adjustable security bindings

Rakis implements an embedding based consensus mechanism with a commit-reveal system. On-chain contracts (like this one that’s deployed to a testnet on Arbirtrum) or peers in the network fire off inference requests, which specify the parameters (prompt, temperature, etc) and a security frame. The security frame is intended to make consensus looser or tighter, so that applications with higher security (and determinism) needs can spend more for more compute, while other dApps with simpler needs (write me the next chapter of this NFT) can choose faster, cheaper methods.

Inference requests are picked up by nodes on the network (the browser tabs, of which you’re hopefully now one) and executed when they can. Requests expire after a certain time period, at which point the security frame is used to figure out if we can run consensus. The Security Frame has the following adjustable parameters:
The Quorum Size: How many different nodes need to run this inference within the time for it to be valid?
SecDistance: How similar do the results need to be? We define this as a distance.
SecPercentage: What percentage of the participants need to be within this distance? How many outliers/bad actors can we tolerate?

For example, a simple creative project that attempts to write a custom story based on a user’s transacton history, or a smart contract that merges two game cards together to get new traits might specify a lower quorum size, a wider SecDistance, and a lower SecPercentage. A financial project that evaluates incoming grant proposals or parses pdfs would do the opposite.


During the time allotted for inference, participants exchange hashes that irreversibly represent their results. This is known as a commit, and locks them in to a certain result without being able to copy anyone else’s.

When this time ends, if there are enough commits, nodes form a quorum, and request a reveal. Once all outputs are revealed, they’re verified to the commit, and consensus starts.

The implemented consensus mechanism is simple. The outputs are embedded (with the use of [binary embeddings] which have proved relatively deterministic in our tests), and the embedding clusters are used as measure of agreement. We try to find the location of a sphere of radius SecDistance that has the highest number of points, in high dimensional embedding space. Inference outputs outside this sphere are considered failing, and the rest are deterministically hashed for a source of randomness to select one.

[Picture]

This is simple, but functional - and extensible. You can check the code for a commented discussion on other methods (like [DBSCAN]) and the implications therein. Here are some easy upgrades:
Improved clustering algorithms that extend the consensus window or reduce it depending on the application.
Comparisons for semistructured output. Rakis may already support JSON mode by the time this post is live, but being able to combine exact match in structured fields (like booleans) with fuzzy comparison would be super useful.
Requesting multiple embedding models - see the section on [Heterogeneity is a strength] for why multiple models on the same request can be useful.
Small models as evaluators - [the original discussion] about this project had the idea of using tiny, tiny models (1.5B-2B) with constrained output (yes/no all the way to JSON) as a way to get deterministic comparisons, which could then be MapReduced down to do consensus on larger lists of outputs. If that sentence was confusing I’m sorry - and let me know! I might write a different post about that one.

## An oracle for embeddable data

If you’ve already heard me talk about this, you might have also realised that this is a method for connecting varying sources of text/embeddable information into a decentralized network - it needn’t be limited to AI inference outputs. If this works - and it’s a big if - it opens the door to a lot more data streams. Fuzzy information like news sources, earnings reports, etc have previously been [very hard to connect] to decentralized systems because there haven’t been good ways to coalesce multiple sources of data that aren’t structured or numeric.

Here’s something else we can do (that was almost a functioning part of the codebase): if you have a decentralized oracle, you can trustlessly add in centralized models. What if nodes plugged in an OpenAI or Anthropic key, and on-chain smart contracts could call the absolute best models humanity has developed? Barring the problem of transaction replayability in the future (due to deprecated models), this might be a good idea. I’m still on the fence as to whether we gain more than we lose here - leaning for rather than against tonight.

## Adversarial prompt engineering

Vitalik (and others) are right to point out that prompt-engineering and other counter-ML attacks are viable surfaces, that will start being used as soon as its economically useful to do so. [customer service bot problem] is a good example.

[picture]

However, if you have a method of consensus that actually favors non-determinism (and later we’ll see if we can actually reward it), there’s a solution: spread out your model selection. Rakis today allows you to send an inference request with multiple models at the same time. Nodes can choose any model they’d like (which might cause them to pick the cheapest one, but this can be incentivized against pretty easily), and heterogeneity in the underlying models is a good thing. The thesis is that finding prompt-engineering and other ML attacks across the entire surface area of a bunch of models is harder than discovering reliable attacks against one model. Also because we repeat inferences many, *many* times, tuning consensus - either on the caller’s side or the network’s - to preferentially reject bad outputs would be a viable target to work on.

In simple terms: Being able to run more copies of the same inference on a large number of models should make attacks harder.

Now about the things I couldn’t realistically get to in ten days:

# Unimplemented Solutions

## Sybil inferencing

The simple way to solve Sybil here is to run validator nodes - like (sigh) [Hyperledger]. Known large organizations (like the Solana and Ethereum foundations) can run nodes that validate outputs by rerunning inferences. This would work, but it would impose an upper cap on the throughput of the network (what the validator nodes could validate in reasonable time) and give up some of the guarantees of decentralization we could get.

An untested solution (which could use its own post) is to take advantage of heterogeneity. This is hard to explain in a single paragraph, but there might be functions that reward a difference in output - in embedding space, it mathematically possible to say that your reward for an inference should be proportional to how dissimilar your output was to everyone else’s, while still being within the valid cluster. I think it should also be possible (again, untested) to then adjust those incentives that copying your output 20 times nets you the same amount as submitting it once.

A third solution is staking and verification-based slashing. Because we have stronger replay capabilities with this consensus method, nodes can challenge inferences, pick nodes that weren’t part of the original inference with some reputation to verify, and use the results to slash some precommitted stake, all without much trouble. However, prevention is always better than curing things after the fact, and I’ve always thought that staking works rarely - and even when it does it simply puts an economic price on bad behavior, much like a speeding ticket. If you end up connecting your system to things that far outweigh what you can penalize someone for, you’re almost asking them to take advantage of that arbitrage in stakes.


## Why I’m releasing Rakis

So, why release it? I usually build things because they won’t leave me alone until they take some kind of form. In this case, nothing I’ve said above is a certainty - these are all theory. Byzantine environments are hell for the best-made plans - and there’s no real alternative to a field test. With large decentralized consensus mechanisms, fail often, fail early is the right way to go. I’m interested in how far Rakis gets before it fails - and why it’ll fail.

Additionally, there’s a discord - and I’m hoping it (or something like it somewhere) becomes a lighting rod for the singular conversation of permissionless decentralized inference for smart contracts. If one of us can get it to work, I think this new instruction set of prompting can actually, finally realize the vision that once existed about self-executing code that could be companies.

If that doesn’t happen, maybe it could be a conversation spot to discuss inference in the browser. This is still pretty slept on - the future I think has orders of magnitude more AIs functioning completely in the browser, and I’d like to find more people who can’t sleep because of that thought.

## What you can do

For one, use it! Tell me what you think [on Twitter]. You can also help the project by pushing [adding a star], or a PR for any of the [big or small TODOs].

What we badly need is a better UI. I’m not terrible at building interfaces, but it takes me forever - open to anyone taking a shot at it.

Rakis is also pretty extensible - and intentionally built on a layered architecture. We already use five different P2P networks for redundant message delivery (more on the architecture in another post), so it’s easy to add more networks, more chains, more contract specs, more models and execution engines, more support for more things!

You can also very easily fork the Rakis network. If you run this code in devtools (Cmd+Option+A) and reload, you’ll effectively have your own private Rakis network. Only people with your network name can find your peers, and you guys can have your own little party in there.

</IntroPost>